{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Younes-khadraoui/place-recognition/blob/master/Place_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3HuIYWJKjsc"
      },
      "source": [
        "# Buildings detection, Image stitching and place recognition using sift/VLAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY5GyyGsKjsn"
      },
      "source": [
        "### The user gives an input image and the model recognizes the place ( math, info faculties  ... )\n",
        "\n",
        "### And predict whether the input image contains a building or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRbn61eKKjso"
      },
      "source": [
        "#### Step 1\n",
        "* Build a panoramic dataset, using the videos dataset , there is 4 faculties, a video for each facult√©\n",
        "* each video we extract some frames from it (frames should not be so close nor too far)\n",
        "* from these frame we make an panoramic image ( image stitching )\n",
        "\n",
        "\n",
        "### Step 2\n",
        "* There we extract image features from each panoramic image using SIFT ( and save them in an .npz  file)\n",
        "* when the user gives an input image we extract its features using SIFT too\n",
        "* And we compare with each saved features (.npz)\n",
        "* Then we classify it with the one that has many simillar features\n",
        "\n",
        "### Step 3\n",
        "* for building detection we use image segmentation using a pre-trained model from facebook ( detectron2 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file and the extraction directory\n",
        "zip_file_path = '/content/data.zip'\n",
        "extract_dir = '/content'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir)\n",
        "\n",
        "# Extract the zip file\n",
        "print(zip_file_path)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# List the contents of the extraction directory\n",
        "extracted_files = os.listdir(extract_dir)\n",
        "print(\"Extracted files:\", extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zUyhMzhKWqJx",
        "outputId": "ce7afc7a-7ec2-42b5-bb1b-fa530b31d4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-750a5dabb834>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Extract the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoV0zDM6Kjsq"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"frames\"):\n",
        "    os.mkdir(\"frames\")\n",
        "\n",
        "video_files = [\n",
        "    \"/content/data/VID_20240407_163907.mp4\",\n",
        "    \"/content/data/VID_20240407_163620.mp4\",\n",
        "    \"/content/data/VID_20240407_163452.mp4\",\n",
        "    \"/content/data/VID_20240407_163112.mp4\"\n",
        "]\n",
        "\n",
        "num_frames = 34\n",
        "\n",
        "stitcher = cv.Stitcher_create()  # create a stitcher object\n",
        "\n",
        "j = 0\n",
        "for video_file in video_files:\n",
        "\n",
        "    video_info = cv.VideoCapture(video_file)\n",
        "\n",
        "    total_frames = int(video_info.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"total frames: {total_frames}\")\n",
        "\n",
        "    interval = total_frames // num_frames\n",
        "\n",
        "    print(f\"interval: {interval}\")\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    if not os.path.exists(f'frames/{j}'):\n",
        "        os.mkdir(f'frames/{j}')\n",
        "    else:\n",
        "        for file in os.listdir(f'frames/{j}'):\n",
        "            os.remove(os.path.join(f'frames/{j}', file))\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        video_info.set(cv.CAP_PROP_POS_FRAMES, i * interval)\n",
        "\n",
        "        ret, frame = video_info.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_name = f'frames/{j}/{os.path.basename(video_file)}_frame_{i}.jpg'\n",
        "\n",
        "        cv.imwrite(frame_name, frame)\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "    video_info.release()\n",
        "\n",
        "    status, panorama = stitcher.stitch(frames)\n",
        "\n",
        "    if status == cv.Stitcher_OK:\n",
        "        panorama_name = f'panoramas/{j}_panorama.jpg'\n",
        "        cv.imwrite(panorama_name, panorama)\n",
        "        print(f\"Panorama {j} stitched successfully.\")\n",
        "    else:\n",
        "        print(f\"Error stitching panorama {j}: {status}\")\n",
        "\n",
        "    j += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BtP1ZUUKjsv"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"cropped\"):\n",
        "    os.mkdir(\"cropped\")\n",
        "\n",
        "panorama_files = [\n",
        "    \"/content/panoramas/0_panorama.jpg\",\n",
        "    \"/content/panoramas/1_panorama.jpg\",\n",
        "    \"/content/panoramas/2_panorama.jpg\",\n",
        "    \"/content/panoramas/3_panorama.jpg\"\n",
        "]\n",
        "\n",
        "for idx, panorama_file in enumerate(panorama_files):\n",
        "\n",
        "    panorama = cv.imread(panorama_file)\n",
        "\n",
        "    if panorama is None:\n",
        "        print(f\"Error reading panorama {idx}.\")\n",
        "        continue\n",
        "\n",
        "    # Crop the panorama image by removing 100 pixels from each side\n",
        "    h, w = panorama.shape[:2]\n",
        "    panorama_cropped = panorama[115:h-160, 100:w-100]\n",
        "\n",
        "    cropped_name = f'cropped/{idx}_panorama_cropped.jpg'\n",
        "    cv.imwrite(cropped_name, panorama_cropped)\n",
        "    print(f\"Cropped panorama {idx} saved successfully in cropped_images folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZms8oAAKjsy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "panorama_images = [\n",
        "    \"/content/cropped/0_panorama_cropped.jpg\",\n",
        "    \"/content/cropped/1_panorama_cropped.jpg\",\n",
        "    \"/content/cropped/2_panorama_cropped.jpg\",\n",
        "    \"/content/cropped/3_panorama_cropped.jpg\"\n",
        "]\n",
        "\n",
        "i = 0\n",
        "for image in panorama_images:\n",
        "    panorama = cv2.imread(image)\n",
        "\n",
        "    # Create SIFT object\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints, descriptors = sift.detectAndCompute(panorama, None)\n",
        "\n",
        "    # Extract keypoint information\n",
        "    keypoint_coords = np.array([kp.pt for kp in keypoints])\n",
        "    keypoint_sizes = np.array([kp.size for kp in keypoints])\n",
        "    keypoint_angles = np.array([kp.angle for kp in keypoints])\n",
        "    keypoint_responses = np.array([kp.response for kp in keypoints])\n",
        "\n",
        "    # Save keypoints and descriptors to a .npz file\n",
        "    np.savez(f'{i}_panorama_features.npz',\n",
        "            keypoint_coords=keypoint_coords,\n",
        "            keypoint_sizes=keypoint_sizes,\n",
        "            keypoint_angles=keypoint_angles,\n",
        "            keypoint_responses=keypoint_responses,\n",
        "            descriptors=descriptors)\n",
        "\n",
        "    # Draw keypoints on the panorama image\n",
        "    panorama_with_keypoints = cv2.drawKeypoints(panorama, keypoints, None)\n",
        "\n",
        "    cv2.imshow('Panorama with Keypoints', panorama_with_keypoints)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ9lZ9Q1Kjs1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "input_image_path = \"/content/data/IMG_20240407_163146.jpg\"\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "# Create SIFT object\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "# Detect keypoints and compute descriptors for the input image\n",
        "input_keypoints, input_descriptors = sift.detectAndCompute(input_image, None)\n",
        "\n",
        "# Draw keypoints on the input image\n",
        "input_image_with_keypoints = cv2.drawKeypoints(input_image, input_keypoints, None)\n",
        "\n",
        "# Resize window to fit the image dimensions\n",
        "cv2.namedWindow('Input Image with Keypoints', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Input Image with Keypoints', input_image.shape[1], input_image.shape[0])\n",
        "\n",
        "# Display the input image with keypoints\n",
        "cv2.imshow('Input Image with Keypoints', input_image_with_keypoints)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skucaGJ-Kjs2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# FLANN-based matcher\n",
        "flann = cv2.FlannBasedMatcher()\n",
        "\n",
        "best_match_count = 0\n",
        "best_match_image = None\n",
        "\n",
        "cropped_npz_files = [\n",
        "    \"0_panorama_features.npz\",\n",
        "    \"1_panorama_features.npz\",\n",
        "    \"2_panorama_features.npz\",\n",
        "    \"3_panorama_features.npz\"\n",
        "]\n",
        "\n",
        "for npz_file in cropped_npz_files:\n",
        "    panorama_data = np.load(npz_file)\n",
        "    keypoints = [cv2.KeyPoint(x[0], x[1], _size, _angle, _response)\n",
        "                 for x, _size, _angle, _response in\n",
        "                 zip(panorama_data['keypoint_coords'],\n",
        "                     panorama_data['keypoint_sizes'],\n",
        "                     panorama_data['keypoint_angles'],\n",
        "                     panorama_data['keypoint_responses'])]\n",
        "    descriptors = panorama_data['descriptors']\n",
        "\n",
        "    matches = flann.knnMatch(input_descriptors, descriptors, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.7 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > best_match_count:\n",
        "        best_match_count = len(good_matches)\n",
        "        best_match_image = os.path.join(\"/content/cropped\", npz_file.replace(\"_features.npz\", \"_cropped.jpg\"))\n",
        "\n",
        "print(\"the best match is \" ,best_match_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-hVkAYcKjs5"
      },
      "source": [
        "### Panoptic segmentation is a technique that combines 2 segmentation approaches:\n",
        "\n",
        "* Instance Segmentation: Identifies individual objects and assigns a unique label to each instance (e.g., car1, car2, person1).\n",
        "* Semantic Segmentation: Classifies each pixel in the image into a semantic category (e.g., building, road, sky)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1AB8GMIOObp"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"/content/detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('/content/detectron2'))\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
        "!pip install -e detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RnxCZ_W91ZF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import cv2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def detect_and_classify_buildings(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (800, 600))\n",
        "\n",
        "    cfg = get_cfg()\n",
        "\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "    cfg.MODEL.DEVICE = \"cpu\"\n",
        "\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "\n",
        "    panoptic_seg, segments_info = predictor(image)[\"panoptic_seg\"]\n",
        "\n",
        "    stuff_classes = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).stuff_classes\n",
        "\n",
        "    # Filter by buildings :)\n",
        "    building_segments = [seg for seg in segments_info if seg[\"category_id\"] < len(stuff_classes) and stuff_classes[seg[\"category_id\"]] == \"building\"]\n",
        "\n",
        "    total_building_area = sum([seg[\"area\"] for seg in building_segments])\n",
        "\n",
        "    print(total_building_area)\n",
        "\n",
        "    if total_building_area == 0:\n",
        "        print(\"The image does not contain buildings.\")\n",
        "    elif total_building_area > 30000:\n",
        "        print(\"The image contains most buildings.\")\n",
        "    else:\n",
        "        print(\"The image contains some buildings.\")\n",
        "\n",
        "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "    out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "image_file = \"/content/data/IMG_20240407_163935.jpg\"\n",
        "classification = detect_and_classify_buildings(image_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}